{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_inception_v2_coco_2017_11_17'\n",
    "# high accuracy but very slow\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_resnet101_coco_2017_11_08'\n",
    "\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "    file_name = os.path.basename(file.name)\n",
    "    if 'frozen_inference_graph.pb' in file_name:\n",
    "        tar_file.extract(file, os.getcwd())\n",
    "    \n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "sess = tf.Session(graph=detection_graph)\n",
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255   \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://192.168.137.170:8080/shot.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 960, 3)\n",
      "700 740\n",
      "0.031876594\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 143 598\n",
      "ymin, ymax : 212 661\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.7057259\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 126 607\n",
      "ymin, ymax : 141 651\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.7972405\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 123 608\n",
      "ymin, ymax : 143 648\n",
      "inif\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.71230537\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 120 608\n",
      "ymin, ymax : 148 641\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.13128263\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 142 646\n",
      "ymin, ymax : 226 679\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.40034497\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 150 594\n",
      "ymin, ymax : 283 676\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.20780098\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 414 588\n",
      "ymin, ymax : 181 442\n",
      "move LEFT - 1st !!!\n",
      "700 740\n",
      "0.17412579\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 304 434\n",
      "ymin, ymax : 489 655\n",
      "move LEFT - 1st !!!\n",
      "700 740\n",
      "0.20000592\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 423 592\n",
      "ymin, ymax : 149 369\n",
      "move LEFT - 1st !!!\n",
      "700 740\n",
      "0.5528686\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 116 607\n",
      "ymin, ymax : 110 658\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.77152526\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 128 606\n",
      "ymin, ymax : 124 641\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.12120822\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 171 617\n",
      "ymin, ymax : 119 660\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.4831322\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 159 331\n",
      "ymin, ymax : 411 638\n",
      "move Right - 2nd !!!\n",
      "700 740\n",
      "0.41586322\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 157 611\n",
      "ymin, ymax : 142 556\n",
      "STOPPPPPP !!!! - 3nd !!!\n",
      "700 740\n",
      "0.9816803\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 412 588\n",
      "ymin, ymax : 268 640\n",
      "inif\n",
      "move LEFT - 1st !!!\n",
      "700 740\n",
      "0.98179126\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 412 589\n",
      "ymin, ymax : 266 641\n",
      "inif\n",
      "move LEFT - 1st !!!\n",
      "700 740\n",
      "0.9821203\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 420 588\n",
      "ymin, ymax : 261 621\n",
      "inif\n",
      "move LEFT - 1st !!!\n",
      "700 740\n",
      "0.9578342\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 428 591\n",
      "ymin, ymax : 260 616\n",
      "inif\n",
      "move LEFT - 1st !!!\n"
     ]
    }
   ],
   "source": [
    "# video = cv2.VideoCapture('test_video_1.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "imgresp=urllib.request.urlopen(url)\n",
    "imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "frame=cv2.imdecode(imgno,-1)\n",
    "frame=cv2.transpose(frame)\n",
    "frame=cv2.flip(frame,flipCode=1)\n",
    "print(frame.shape)\n",
    "frame_width = frame.shape[0]\n",
    "frame_height = frame.shape[1]\n",
    "\n",
    "# frame_width = int(video.get(3))\n",
    "# frame_height = int(video.get(4))\n",
    "\n",
    "#out = cv2.VideoWriter('output.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "# out = cv2.VideoWriter('outpy.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame_width,frame_height))\n",
    "#ut = cv2.VideoWriter('output_video.avi',cv2.VideoWriter_fourcc(*'MJPG',20,(1280,960)))\n",
    "while(True):\n",
    "    imgresp=urllib.request.urlopen(url)\n",
    "    imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "    frame=cv2.imdecode(imgno,-1)\n",
    "    frame=cv2.transpose(frame)\n",
    "    frame=cv2.flip(frame,flipCode=1)\n",
    "    frame = cv2.resize(frame, (740,700))\n",
    "    #print(frame.shape)\n",
    "    #ret, frame = video.read()\n",
    "    stime = time.time()\n",
    "    objects = []\n",
    "    class_str = \"\"\n",
    "    frame_width = frame.shape[0]\n",
    "    frame_height = frame.shape[1]\n",
    "    rows, cols = frame.shape[:2]\n",
    "    left_boundary = [int(cols*0.40), int(rows*0.95)]\n",
    "    left_boundary_top = [int(cols*0.40), int(rows*0.20)]\n",
    "    right_boundary = [int(cols*0.60), int(rows*0.95)]\n",
    "    right_boundary_top = [int(cols*0.60), int(rows*0.20)]\n",
    "    bottom_left  = [int(cols*0.20), int(rows*0.95)]\n",
    "    top_left     = [int(cols*0.20), int(rows*0.20)]\n",
    "    bottom_right = [int(cols*0.80), int(rows*0.95)]\n",
    "    top_right    = [int(cols*0.80), int(rows*0.20)]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "    cv2.line(frame,tuple(bottom_left),tuple(bottom_right), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(bottom_right),tuple(top_right), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(top_left),tuple(bottom_left), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(top_left),tuple(top_right), (255, 0, 0), 5)\n",
    "    copied = np.copy(frame)\n",
    "    interested = region_of_interest(copied,vertices)\n",
    "    frame_expanded = np.expand_dims(interested, axis=0)\n",
    "\n",
    "    (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections],feed_dict={image_tensor: frame_expanded})\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        frame,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.78)\n",
    "    print(frame_width,frame_height)\n",
    "    ymin = int((boxes[0][0][0]*frame_width))\n",
    "    xmin = int((boxes[0][0][1]*frame_height))\n",
    "    ymax = int((boxes[0][0][2]*frame_width))\n",
    "    xmax = int((boxes[0][0][3]*frame_height))\n",
    "    Result = np.array(frame[ymin:ymax,xmin:xmax])\n",
    "\n",
    "    ymin_str='y min  = %.2f '%(ymin)\n",
    "    ymax_str='y max  = %.2f '%(ymax)\n",
    "    xmin_str='x min  = %.2f '%(xmin)\n",
    "    xmax_str='x max  = %.2f '%(xmax)\n",
    "\n",
    "    cv2.putText(frame,ymin_str, (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "    cv2.putText(frame,ymax_str, (50, 70),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "    cv2.putText(frame,xmin_str, (50, 90),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "    cv2.putText(frame,xmax_str, (50, 110),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "    print(scores.max())\n",
    "\n",
    "    print(\"left_boundary[0],right_boundary[0] :\", left_boundary[0], right_boundary[0])\n",
    "    print(\"left_boundary[1],right_boundary[1] :\", left_boundary[1], right_boundary[1])\n",
    "    print(\"xmin, xmax :\", xmin, xmax)\n",
    "    print(\"ymin, ymax :\", ymin, ymax)\n",
    "    if scores.max() > 0.78:\n",
    "        print(\"inif\")\n",
    "    if(xmin >= left_boundary[0]):\n",
    "        print(\"move LEFT - 1st !!!\")\n",
    "        cv2.putText(frame,'Move LEFT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "    elif(xmax <= right_boundary[0]):\n",
    "        print(\"move Right - 2nd !!!\")\n",
    "        cv2.putText(frame,'Move RIGHT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "    elif(xmin <= left_boundary[0] and xmax >= right_boundary[0]):\n",
    "        print(\"STOPPPPPP !!!! - 3nd !!!\")\n",
    "        cv2.putText(frame,' STOPPPPPP!!!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "\n",
    "    \n",
    "    cv2.line(frame,tuple(left_boundary),tuple(left_boundary_top), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(right_boundary),tuple(right_boundary_top), (255, 0, 0), 5)\n",
    "   # out.write(frame)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # video = cv2.VideoCapture('test_video_1.mp4')\n",
    "# def worker():\n",
    "#     print(\"cdanmck\")\n",
    "#     url=\"http://192.168.137.38:8080/shot.jpg\"\n",
    "\n",
    "#     # video = cv2.VideoCapture('test_video_1.mp4')\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#     imgresp=urllib.request.urlopen(url)\n",
    "#     imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "#     frame=cv2.imdecode(imgno,-1)\n",
    "#     frame=cv2.transpose(frame)\n",
    "#     frame=cv2.flip(frame,flipCode=1)\n",
    "#     print(frame.shape)\n",
    "#     frame_width = frame.shape[0]\n",
    "#     frame_height = frame.shape[1]\n",
    "\n",
    "#     # frame_width = int(video.get(3))\n",
    "#     # frame_height = int(video.get(4))\n",
    "\n",
    "#     #out = cv2.VideoWriter('output.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "#     # out = cv2.VideoWriter('outpy.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame_width,frame_height))\n",
    "#     #ut = cv2.VideoWriter('output_video.avi',cv2.VideoWriter_fourcc(*'MJPG',20,(1280,960)))\n",
    "#     while(True):\n",
    "#         imgresp=urllib.request.urlopen(url)\n",
    "#         imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "#         frame=cv2.imdecode(imgno,-1)\n",
    "#         frame=cv2.transpose(frame)\n",
    "#         frame=cv2.flip(frame,flipCode=1)\n",
    "#         frame = cv2.resize(frame, (740,700))\n",
    "#         #print(frame.shape)\n",
    "#         #ret, frame = video.read()\n",
    "#         stime = time.time()\n",
    "#         objects = []\n",
    "#         class_str = \"\"\n",
    "#         frame_width = frame.shape[0]\n",
    "#         frame_height = frame.shape[1]\n",
    "#         rows, cols = frame.shape[:2]\n",
    "#         left_boundary = [int(cols*0.40), int(rows*0.95)]\n",
    "#         left_boundary_top = [int(cols*0.40), int(rows*0.20)]\n",
    "#         right_boundary = [int(cols*0.60), int(rows*0.95)]\n",
    "#         right_boundary_top = [int(cols*0.60), int(rows*0.20)]\n",
    "#         bottom_left  = [int(cols*0.20), int(rows*0.95)]\n",
    "#         top_left     = [int(cols*0.20), int(rows*0.20)]\n",
    "#         bottom_right = [int(cols*0.80), int(rows*0.95)]\n",
    "#         top_right    = [int(cols*0.80), int(rows*0.20)]\n",
    "#         vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "#         cv2.line(frame,tuple(bottom_left),tuple(bottom_right), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(bottom_right),tuple(top_right), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(top_left),tuple(bottom_left), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(top_left),tuple(top_right), (255, 0, 0), 5)\n",
    "#         copied = np.copy(frame)\n",
    "#         interested = region_of_interest(copied,vertices)\n",
    "#         frame_expanded = np.expand_dims(interested, axis=0)\n",
    "\n",
    "#         (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections],feed_dict={image_tensor: frame_expanded})\n",
    "\n",
    "#         vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#             frame,\n",
    "#             np.squeeze(boxes),\n",
    "#             np.squeeze(classes).astype(np.int32),\n",
    "#             np.squeeze(scores),\n",
    "#             category_index,\n",
    "#             use_normalized_coordinates=True,\n",
    "#             line_thickness=8,\n",
    "#             min_score_thresh=0.78)\n",
    "#         for i,b in enumerate(boxes[0]):\n",
    "#             if scores[0][i] >= 0.5:\n",
    "#                 mid_x = (boxes[0][i][1]+boxes[0][i][3])/2\n",
    "#                 mid_y = (boxes[0][i][0]+boxes[0][i][2])/2\n",
    "#                 apx_distance = round(((1 - (boxes[0][i][3] - boxes[0][i][1]))**4),1)\n",
    "#                 cv2.putText(frame, '{}'.format(apx_distance), (int(mid_x*800),int(mid_y*450)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "#                 if apx_distance <=0.5:\n",
    "#                     if mid_x > 0.3 and mid_x < 0.7:\n",
    "#                         print(\"\")\n",
    "#                         #cv2.putText(frame, 'WARNING!!!', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3)\n",
    "#         print(frame_width,frame_height)\n",
    "#         ymin = int((boxes[0][0][0]*frame_width))\n",
    "#         xmin = int((boxes[0][0][1]*frame_height))\n",
    "#         ymax = int((boxes[0][0][2]*frame_width))\n",
    "#         xmax = int((boxes[0][0][3]*frame_height))\n",
    "#         Result = np.array(frame[ymin:ymax,xmin:xmax])\n",
    "\n",
    "#         ymin_str='y min  = %.2f '%(ymin)\n",
    "#         ymax_str='y max  = %.2f '%(ymax)\n",
    "#         xmin_str='x min  = %.2f '%(xmin)\n",
    "#         xmax_str='x max  = %.2f '%(xmax)\n",
    "\n",
    "#         cv2.putText(frame,ymin_str, (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         cv2.putText(frame,ymax_str, (50, 70),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         cv2.putText(frame,xmin_str, (50, 90),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         cv2.putText(frame,xmax_str, (50, 110),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         print(scores.max())\n",
    "\n",
    "#         print(\"left_boundary[0],right_boundary[0] :\", left_boundary[0], right_boundary[0])\n",
    "#         print(\"left_boundary[1],right_boundary[1] :\", left_boundary[1], right_boundary[1])\n",
    "#         print(\"xmin, xmax :\", xmin, xmax)\n",
    "#         print(\"ymin, ymax :\", ymin, ymax)\n",
    "#         if scores.max() > 0.78:\n",
    "#             engine.say(\"Go on\")\n",
    "#             print(\"GO ON!\")\n",
    "#         if(xmin >= left_boundary[0]):\n",
    "#             engine.say(\"move left\")\n",
    "#             print(\"MOVE LEFT\")\n",
    "#             cv2.putText(frame,'Move LEFT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "#         elif(xmax <= right_boundary[0]):\n",
    "#             engine.say(\"move right\")\n",
    "#             print(\"MOVE RIGHT!!\")\n",
    "#             cv2.putText(frame,'Move RIGHT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "#         elif(xmin <= left_boundary[0] and xmax >= right_boundary[0]):\n",
    "#             #engine.say(\"stop\")\n",
    "#             voice()\n",
    "#             print(\"STOP!!\")\n",
    "#             cv2.putText(frame,' STOPPPPPP!!!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "\n",
    "\n",
    "#         cv2.line(frame,tuple(left_boundary),tuple(left_boundary_top), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(right_boundary),tuple(right_boundary_top), (255, 0, 0), 5)\n",
    "#        # out.write(frame)\n",
    "#         #engine.runAndWait()\n",
    "\n",
    "#         cv2.imshow('frame',frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     cv2.destroyAllWindows()\n",
    "# def voice():\n",
    "#     engie.say(\"Hello World\")\n",
    "#     engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     if __name__ == \"__main__\":\n",
    "#         p1 = multiprocessing.Process(target=worker)\n",
    "#         p2 = multiprocessing.Process(target=voice)\n",
    "#         p1.start()\n",
    "#         p2.start()\n",
    "#         worker()\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
