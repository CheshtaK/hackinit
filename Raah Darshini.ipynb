{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_inception_v2_coco_2017_11_17'\n",
    "# high accuracy but very slow\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_resnet101_coco_2017_11_08'\n",
    "\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "    file_name = os.path.basename(file.name)\n",
    "    if 'frozen_inference_graph.pb' in file_name:\n",
    "        tar_file.extract(file, os.getcwd())\n",
    "    \n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "sess = tf.Session(graph=detection_graph)\n",
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255   \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f78047dec616>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfourcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoWriter_fourcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m'XVID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mframe_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mframe_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "\n",
    "# out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "# out = cv2.VideoWriter('outpy.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame_width,frame_height))\n",
    "out = cv2.VideoWriter('output_video.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 20 , (frame_width,frame_height))\n",
    "try:\n",
    "    while(video.isOpened()):\n",
    "        \n",
    "        ret, frame = video.read()\n",
    "        stime = time.time()\n",
    "        objects = []\n",
    "        class_str = \"\"\n",
    "        frame_width = frame.shape[0]\n",
    "        frame_height = frame.shape[1]\n",
    "        \n",
    "        rows, cols = frame.shape[:2]\n",
    "        \n",
    "        left_boundary = [int(cols*0.40), int(rows*0.95)]\n",
    "        left_boundary_top = [int(cols*0.40), int(rows*0.20)]\n",
    "        right_boundary = [int(cols*0.60), int(rows*0.95)]\n",
    "        right_boundary_top = [int(cols*0.60), int(rows*0.20)]\n",
    "        \n",
    "        bottom_left  = [int(cols*0.20), int(rows*0.95)]\n",
    "        top_left     = [int(cols*0.20), int(rows*0.20)]\n",
    "        bottom_right = [int(cols*0.80), int(rows*0.95)]\n",
    "        top_right    = [int(cols*0.80), int(rows*0.20)]\n",
    "        vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "      \n",
    "        cv2.line(frame,tuple(bottom_left),tuple(bottom_right), (255, 0, 0), 5)\n",
    "        cv2.line(frame,tuple(bottom_right),tuple(top_right), (255, 0, 0), 5)\n",
    "        cv2.line(frame,tuple(top_left),tuple(bottom_left), (255, 0, 0), 5)\n",
    "        cv2.line(frame,tuple(top_left),tuple(top_right), (255, 0, 0), 5)\n",
    "        \n",
    "        copied = np.copy(frame)\n",
    "        interested = region_of_interest(copied,vertices)\n",
    "        \n",
    "        frame_expanded = np.expand_dims(interested, axis=0)\n",
    "\n",
    "        (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections],feed_dict={image_tensor: frame_expanded})\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            frame,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8,\n",
    "            min_score_thresh=0.78)\n",
    "        \n",
    "        print(frame_width,frame_height)\n",
    "        \n",
    "        ymin = int((boxes[0][0][0]*frame_width))\n",
    "        xmin = int((boxes[0][0][1]*frame_height))\n",
    "        ymax = int((boxes[0][0][2]*frame_width))\n",
    "        xmax = int((boxes[0][0][3]*frame_height))\n",
    "        \n",
    "        Result = np.array(frame[ymin:ymax,xmin:xmax])\n",
    "\n",
    "        ymin_str='y min  = %.2f '%(ymin)\n",
    "        ymax_str='y max  = %.2f '%(ymax)\n",
    "        xmin_str='x min  = %.2f '%(xmin)\n",
    "        xmax_str='x max  = %.2f '%(xmax)\n",
    "\n",
    "        cv2.putText(frame,ymin_str, (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "        cv2.putText(frame,ymax_str, (50, 70),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "        cv2.putText(frame,xmin_str, (50, 90),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "        cv2.putText(frame,xmax_str, (50, 110),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "        \n",
    "        print(scores.max())\n",
    "      \n",
    "        print(\"left_boundary[0],right_boundary[0] :\", left_boundary[0], right_boundary[0])\n",
    "        print(\"left_boundary[1],right_boundary[1] :\", left_boundary[1], right_boundary[1])\n",
    "        print(\"xmin, xmax :\", xmin, xmax)\n",
    "        print(\"ymin, ymax :\", ymin, ymax)\n",
    "        \n",
    "        if scores.max() > 0.78:\n",
    "            print(\"inif\")\n",
    "        if(xmin >= left_boundary[0]):\n",
    "            print(\"move LEFT - 1st !!!\")\n",
    "            cv2.putText(frame,'Move LEFT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "        elif(xmax <= right_boundary[0]):\n",
    "            print(\"move Right - 2nd !!!\")\n",
    "            cv2.putText(frame,'Move RIGHT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "        elif(xmin <= left_boundary[0] and xmax >= right_boundary[0]):\n",
    "            print(\"STOPPPPPP !!!! - 3nd !!!\")\n",
    "            cv2.putText(frame,' STOPPPPPP!!!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "    \n",
    "        cv2.line(frame,tuple(left_boundary),tuple(left_boundary_top), (255, 0, 0), 5)\n",
    "        cv2.line(frame,tuple(right_boundary),tuple(right_boundary_top), (255, 0, 0), 5)\n",
    "      \n",
    "        out.write(frame)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
