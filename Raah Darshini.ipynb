{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_inception_v2_coco_2017_11_17'\n",
    "# high accuracy but very slow\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_resnet101_coco_2017_11_08'\n",
    "\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "    file_name = os.path.basename(file.name)\n",
    "    if 'frozen_inference_graph.pb' in file_name:\n",
    "        tar_file.extract(file, os.getcwd())\n",
    "    \n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "sess = tf.Session(graph=detection_graph)\n",
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255   \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://192.168.29.180:8080/shot.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 960, 3)\n",
      "700 740\n",
      "0.20046327\n",
      "0.24402264\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 414 589\n",
      "ymin, ymax : 140 283\n",
      "700 740\n",
      "0.23638669\n",
      "0.086363226\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 157 465\n",
      "ymin, ymax : 165 399\n",
      "700 740\n",
      "0.18699163\n",
      "0.2944917\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 146 587\n",
      "ymin, ymax : 130 441\n",
      "700 740\n",
      "0.33507296\n",
      "0.13693437\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 166 368\n",
      "ymin, ymax : 234 472\n",
      "700 740\n",
      "0.19662754\n",
      "0.3856396\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 156 570\n",
      "ymin, ymax : 137 322\n",
      "700 740\n",
      "0.23654401\n",
      "0.8039904\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 250 411\n",
      "ymin, ymax : 165 294\n",
      "700 740\n",
      "0.19021592\n",
      "0.26929915\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 149 585\n",
      "ymin, ymax : 133 434\n",
      "700 740\n",
      "0.19100308\n",
      "0.43037787\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 151 583\n",
      "ymin, ymax : 133 432\n",
      "700 740\n",
      "0.19802138\n",
      "0.30939424\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 143 596\n",
      "ymin, ymax : 138 451\n",
      "700 740\n",
      "0.39114913\n",
      "0.45990813\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 337 485\n",
      "ymin, ymax : 273 429\n",
      "700 740\n",
      "0.28338647\n",
      "0.4392409\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 152 593\n",
      "ymin, ymax : 198 498\n",
      "700 740\n",
      "0.19329083\n",
      "0.637831\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 146 598\n",
      "ymin, ymax : 135 416\n",
      "700 740\n",
      "0.19047226\n",
      "0.18876606\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 150 597\n",
      "ymin, ymax : 133 364\n",
      "700 740\n",
      "0.1925633\n",
      "0.21970469\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 139 587\n",
      "ymin, ymax : 134 333\n",
      "700 740\n",
      "0.45326975\n",
      "0.25244868\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 152 572\n",
      "ymin, ymax : 317 655\n",
      "700 740\n",
      "0.17540203\n",
      "0.2125557\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 145 633\n",
      "ymin, ymax : 122 369\n",
      "700 740\n",
      "0.16178137\n",
      "0.16095793\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 142 611\n",
      "ymin, ymax : 113 647\n",
      "700 740\n",
      "0.2227649\n",
      "0.85096115\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 425 591\n",
      "ymin, ymax : 155 452\n",
      "700 740\n",
      "0.15938875\n",
      "0.66749257\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 141 595\n",
      "ymin, ymax : 111 678\n",
      "700 740\n",
      "0.17778365\n",
      "0.3927334\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 137 601\n",
      "ymin, ymax : 124 395\n",
      "700 740\n",
      "0.29313618\n",
      "0.12775686\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 360 393\n",
      "ymin, ymax : 205 260\n",
      "700 740\n",
      "0.35665473\n",
      "0.36751622\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 160 468\n",
      "ymin, ymax : 249 422\n",
      "700 740\n",
      "0.25858665\n",
      "0.38763762\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 159 361\n",
      "ymin, ymax : 181 496\n",
      "700 740\n",
      "0.48556492\n",
      "0.19415846\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 382 466\n",
      "ymin, ymax : 339 405\n",
      "700 740\n",
      "0.25259417\n",
      "0.18137759\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 433 545\n",
      "ymin, ymax : 176 226\n",
      "700 740\n",
      "0.44176486\n",
      "0.40780318\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 376 452\n",
      "ymin, ymax : 309 367\n",
      "700 740\n",
      "0.46075413\n",
      "0.35802948\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 373 453\n",
      "ymin, ymax : 322 383\n",
      "700 740\n",
      "0.16178271\n",
      "0.37352306\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 153 637\n",
      "ymin, ymax : 113 668\n",
      "700 740\n",
      "0.65193117\n",
      "0.024097353\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 618 740\n",
      "ymin, ymax : 456 700\n",
      "700 740\n",
      "0.17999911\n",
      "0.6151845\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 123 627\n",
      "ymin, ymax : 125 681\n",
      "700 740\n",
      "0.17868182\n",
      "0.66602236\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 121 627\n",
      "ymin, ymax : 125 682\n",
      "700 740\n",
      "0.18207446\n",
      "0.5981784\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 123 626\n",
      "ymin, ymax : 127 681\n",
      "700 740\n",
      "0.18106031\n",
      "0.6790142\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 122 627\n",
      "ymin, ymax : 126 682\n",
      "700 740\n",
      "0.17857662\n",
      "0.54880565\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 121 629\n",
      "ymin, ymax : 125 681\n",
      "700 740\n",
      "0.18086094\n",
      "0.67331874\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 122 627\n",
      "ymin, ymax : 126 682\n",
      "700 740\n",
      "0.1801377\n",
      "0.661137\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 122 627\n",
      "ymin, ymax : 126 682\n",
      "700 740\n",
      "0.1785447\n",
      "0.6486577\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 121 628\n",
      "ymin, ymax : 124 682\n",
      "700 740\n",
      "0.17850637\n",
      "0.6069587\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 121 629\n",
      "ymin, ymax : 124 682\n",
      "700 740\n",
      "0.18017322\n",
      "0.6669711\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 123 627\n",
      "ymin, ymax : 126 682\n",
      "700 740\n",
      "0.18049636\n",
      "0.6325346\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 123 626\n",
      "ymin, ymax : 126 680\n",
      "700 740\n",
      "0.17984495\n",
      "0.65773314\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 122 627\n",
      "ymin, ymax : 125 681\n",
      "700 740\n",
      "0.178256\n",
      "0.5913794\n",
      "left_boundary[0],right_boundary[0] : 296 444\n",
      "left_boundary[1],right_boundary[1] : 665 665\n",
      "xmin, xmax : 121 627\n",
      "ymin, ymax : 124 684\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:726: error: (-215:Assertion failed) !buf.empty() && buf.isContinuous() in function 'cv::imdecode_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d86dcfa2aa62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mimgno\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgno\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflipCode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.0) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:726: error: (-215:Assertion failed) !buf.empty() && buf.isContinuous() in function 'cv::imdecode_'\n"
     ]
    }
   ],
   "source": [
    "# video = cv2.VideoCapture('test_video_1.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "imgresp=urllib.request.urlopen(url)\n",
    "imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "frame=cv2.imdecode(imgno,-1)\n",
    "frame=cv2.transpose(frame)\n",
    "frame=cv2.flip(frame,flipCode=1)\n",
    "print(frame.shape)\n",
    "frame_width = frame.shape[0]\n",
    "frame_height = frame.shape[1]\n",
    "\n",
    "# frame_width = int(video.get(3))\n",
    "# frame_height = int(video.get(4))\n",
    "\n",
    "#out = cv2.VideoWriter('output.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "# out = cv2.VideoWriter('outpy.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame_width,frame_height))\n",
    "#ut = cv2.VideoWriter('output_video.avi',cv2.VideoWriter_fourcc(*'MJPG',20,(1280,960)))\n",
    "while(True):\n",
    "    imgresp=urllib.request.urlopen(url)\n",
    "    imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "    frame=cv2.imdecode(imgno,-1)\n",
    "    frame=cv2.transpose(frame)\n",
    "    frame=cv2.flip(frame,flipCode=1)\n",
    "    frame = cv2.resize(frame, (740,700))\n",
    "    #print(frame.shape)\n",
    "    #ret, frame = video.read()\n",
    "    stime = time.time()\n",
    "    objects = []\n",
    "    class_str = \"\"\n",
    "    frame_width = frame.shape[0]\n",
    "    frame_height = frame.shape[1]\n",
    "    rows, cols = frame.shape[:2]\n",
    "    left_boundary = [int(cols*0.40), int(rows*0.95)]\n",
    "    left_boundary_top = [int(cols*0.40), int(rows*0.20)]\n",
    "    right_boundary = [int(cols*0.60), int(rows*0.95)]\n",
    "    right_boundary_top = [int(cols*0.60), int(rows*0.20)]\n",
    "    bottom_left  = [int(cols*0.20), int(rows*0.95)]\n",
    "    top_left     = [int(cols*0.20), int(rows*0.20)]\n",
    "    bottom_right = [int(cols*0.80), int(rows*0.95)]\n",
    "    top_right    = [int(cols*0.80), int(rows*0.20)]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "    cv2.line(frame,tuple(bottom_left),tuple(bottom_right), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(bottom_right),tuple(top_right), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(top_left),tuple(bottom_left), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(top_left),tuple(top_right), (255, 0, 0), 5)\n",
    "    copied = np.copy(frame)\n",
    "    interested = region_of_interest(copied,vertices)\n",
    "    frame_expanded = np.expand_dims(interested, axis=0)\n",
    "\n",
    "    (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections],feed_dict={image_tensor: frame_expanded})\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        frame,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.78)\n",
    "    print(frame_width,frame_height)\n",
    "    ymin = int((boxes[0][0][0]*frame_width))\n",
    "    print(boxes[0][0][0])\n",
    "    xmin = int((boxes[0][0][1]*frame_height))\n",
    "    ymax = int((boxes[0][0][2]*frame_width))\n",
    "    xmax = int((boxes[0][0][3]*frame_height))\n",
    "    Result = np.array(frame[ymin:ymax,xmin:xmax])\n",
    "\n",
    "    ymin_str='y min  = %.2f '%(ymin)\n",
    "    ymax_str='y max  = %.2f '%(ymax)\n",
    "    xmin_str='x min  = %.2f '%(xmin)\n",
    "    xmax_str='x max  = %.2f '%(xmax)\n",
    "\n",
    "#     cv2.putText(frame,ymin_str, (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#     cv2.putText(frame,ymax_str, (50, 70),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#     cv2.putText(frame,xmin_str, (50, 90),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#     cv2.putText(frame,xmax_str, (50, 110),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "    print(scores.max())\n",
    "\n",
    "    print(\"left_boundary[0],right_boundary[0] :\", left_boundary[0], right_boundary[0])\n",
    "    print(\"left_boundary[1],right_boundary[1] :\", left_boundary[1], right_boundary[1])\n",
    "    print(\"xmin, xmax :\", xmin, xmax)\n",
    "    print(\"ymin, ymax :\", ymin, ymax)\n",
    "    if scores.max() > 0.78:\n",
    "        engine.say(\"Go ON\")\n",
    "        #cv2.putText(frame,'Go ON!', (370, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "        pass\n",
    "    if(xmin >= left_boundary[0]):\n",
    "        engine.say(\"move LEFT\")\n",
    "        cv2.putText(frame,'Move LEFT!', (370, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "    elif(xmax <= right_boundary[0]):\n",
    "        engine.say(\"move Right\")\n",
    "        cv2.putText(frame,'Move RIGHT!', (370, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "    elif(xmin <= left_boundary[0] and xmax >= right_boundary[0]):\n",
    "        engine.say(\"STOP\")\n",
    "        cv2.putText(frame,' STOPP!!', (370, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,0,255),2)\n",
    "\n",
    "    \n",
    "    cv2.line(frame,tuple(left_boundary),tuple(left_boundary_top), (255, 0, 0), 5)\n",
    "    cv2.line(frame,tuple(right_boundary),tuple(right_boundary_top), (255, 0, 0), 5)\n",
    "   # out.write(frame)\n",
    "    \n",
    "    engine.runAndWait()\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # video = cv2.VideoCapture('test_video_1.mp4')\n",
    "# def worker():\n",
    "#     print(\"cdanmck\")\n",
    "#     url=\"http://192.168.137.38:8080/shot.jpg\"\n",
    "\n",
    "#     # video = cv2.VideoCapture('test_video_1.mp4')\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#     imgresp=urllib.request.urlopen(url)\n",
    "#     imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "#     frame=cv2.imdecode(imgno,-1)\n",
    "#     frame=cv2.transpose(frame)\n",
    "#     frame=cv2.flip(frame,flipCode=1)\n",
    "#     print(frame.shape)\n",
    "#     frame_width = frame.shape[0]\n",
    "#     frame_height = frame.shape[1]\n",
    "\n",
    "#     # frame_width = int(video.get(3))\n",
    "#     # frame_height = int(video.get(4))\n",
    "\n",
    "#     #out = cv2.VideoWriter('output.avi',fourcc, 20.0, (frame_width,frame_height))\n",
    "#     # out = cv2.VideoWriter('outpy.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame_width,frame_height))\n",
    "#     #ut = cv2.VideoWriter('output_video.avi',cv2.VideoWriter_fourcc(*'MJPG',20,(1280,960)))\n",
    "#     while(True):\n",
    "#         imgresp=urllib.request.urlopen(url)\n",
    "#         imgno=np.array(bytearray(imgresp.read()),dtype=np.uint8)\n",
    "\n",
    "#         frame=cv2.imdecode(imgno,-1)\n",
    "#         frame=cv2.transpose(frame)\n",
    "#         frame=cv2.flip(frame,flipCode=1)\n",
    "#         frame = cv2.resize(frame, (740,700))\n",
    "#         #print(frame.shape)\n",
    "#         #ret, frame = video.read()\n",
    "#         stime = time.time()\n",
    "#         objects = []\n",
    "#         class_str = \"\"\n",
    "#         frame_width = frame.shape[0]\n",
    "#         frame_height = frame.shape[1]\n",
    "#         rows, cols = frame.shape[:2]\n",
    "#         left_boundary = [int(cols*0.40), int(rows*0.95)]\n",
    "#         left_boundary_top = [int(cols*0.40), int(rows*0.20)]\n",
    "#         right_boundary = [int(cols*0.60), int(rows*0.95)]\n",
    "#         right_boundary_top = [int(cols*0.60), int(rows*0.20)]\n",
    "#         bottom_left  = [int(cols*0.20), int(rows*0.95)]\n",
    "#         top_left     = [int(cols*0.20), int(rows*0.20)]\n",
    "#         bottom_right = [int(cols*0.80), int(rows*0.95)]\n",
    "#         top_right    = [int(cols*0.80), int(rows*0.20)]\n",
    "#         vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "#         cv2.line(frame,tuple(bottom_left),tuple(bottom_right), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(bottom_right),tuple(top_right), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(top_left),tuple(bottom_left), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(top_left),tuple(top_right), (255, 0, 0), 5)\n",
    "#         copied = np.copy(frame)\n",
    "#         interested = region_of_interest(copied,vertices)\n",
    "#         frame_expanded = np.expand_dims(interested, axis=0)\n",
    "\n",
    "#         (boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections],feed_dict={image_tensor: frame_expanded})\n",
    "\n",
    "#         vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#             frame,\n",
    "#             np.squeeze(boxes),\n",
    "#             np.squeeze(classes).astype(np.int32),\n",
    "#             np.squeeze(scores),\n",
    "#             category_index,\n",
    "#             use_normalized_coordinates=True,\n",
    "#             line_thickness=8,\n",
    "#             min_score_thresh=0.78)\n",
    "#         for i,b in enumerate(boxes[0]):\n",
    "#             if scores[0][i] >= 0.5:\n",
    "#                 mid_x = (boxes[0][i][1]+boxes[0][i][3])/2\n",
    "#                 mid_y = (boxes[0][i][0]+boxes[0][i][2])/2\n",
    "#                 apx_distance = round(((1 - (boxes[0][i][3] - boxes[0][i][1]))**4),1)\n",
    "#                 cv2.putText(frame, '{}'.format(apx_distance), (int(mid_x*800),int(mid_y*450)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "#                 if apx_distance <=0.5:\n",
    "#                     if mid_x > 0.3 and mid_x < 0.7:\n",
    "#                         print(\"\")\n",
    "#                         #cv2.putText(frame, 'WARNING!!!', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3)\n",
    "#         print(frame_width,frame_height)\n",
    "#         ymin = int((boxes[0][0][0]*frame_width))\n",
    "#         xmin = int((boxes[0][0][1]*frame_height))\n",
    "#         ymax = int((boxes[0][0][2]*frame_width))\n",
    "#         xmax = int((boxes[0][0][3]*frame_height))\n",
    "#         Result = np.array(frame[ymin:ymax,xmin:xmax])\n",
    "\n",
    "#         ymin_str='y min  = %.2f '%(ymin)\n",
    "#         ymax_str='y max  = %.2f '%(ymax)\n",
    "#         xmin_str='x min  = %.2f '%(xmin)\n",
    "#         xmax_str='x max  = %.2f '%(xmax)\n",
    "\n",
    "#         cv2.putText(frame,ymin_str, (50, 50),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         cv2.putText(frame,ymax_str, (50, 70),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         cv2.putText(frame,xmin_str, (50, 90),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         cv2.putText(frame,xmax_str, (50, 110),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2)\n",
    "#         print(scores.max())\n",
    "\n",
    "#         print(\"left_boundary[0],right_boundary[0] :\", left_boundary[0], right_boundary[0])\n",
    "#         print(\"left_boundary[1],right_boundary[1] :\", left_boundary[1], right_boundary[1])\n",
    "#         print(\"xmin, xmax :\", xmin, xmax)\n",
    "#         print(\"ymin, ymax :\", ymin, ymax)\n",
    "#         if scores.max() > 0.78:\n",
    "#             engine.say(\"Go on\")\n",
    "#             print(\"GO ON!\")\n",
    "#         if(xmin >= left_boundary[0]):\n",
    "#             engine.say(\"move left\")\n",
    "#             print(\"MOVE LEFT\")\n",
    "#             cv2.putText(frame,'Move LEFT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "#         elif(xmax <= right_boundary[0]):\n",
    "#             engine.say(\"move right\")\n",
    "#             print(\"MOVE RIGHT!!\")\n",
    "#             cv2.putText(frame,'Move RIGHT!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "#         elif(xmin <= left_boundary[0] and xmax >= right_boundary[0]):\n",
    "#             #engine.say(\"stop\")\n",
    "#             voice()\n",
    "#             print(\"STOP!!\")\n",
    "#             cv2.putText(frame,' STOPPPPPP!!!', (300, 100),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2)\n",
    "\n",
    "\n",
    "#         cv2.line(frame,tuple(left_boundary),tuple(left_boundary_top), (255, 0, 0), 5)\n",
    "#         cv2.line(frame,tuple(right_boundary),tuple(right_boundary_top), (255, 0, 0), 5)\n",
    "#        # out.write(frame)\n",
    "#         #engine.runAndWait()\n",
    "\n",
    "#         cv2.imshow('frame',frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     cv2.destroyAllWindows()\n",
    "# def voice():\n",
    "#     engie.say(\"Hello World\")\n",
    "#     engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     if __name__ == \"__main__\":\n",
    "#         p1 = multiprocessing.Process(target=worker)\n",
    "#         p2 = multiprocessing.Process(target=voice)\n",
    "#         p1.start()\n",
    "#         p2.start()\n",
    "#         worker()\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
